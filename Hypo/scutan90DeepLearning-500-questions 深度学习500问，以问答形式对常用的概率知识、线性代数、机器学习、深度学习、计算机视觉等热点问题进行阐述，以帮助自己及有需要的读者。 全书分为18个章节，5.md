---
doc_type: hypothesis-highlights
url: >-
  https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md
---

# scutan90/DeepLearning-500-questions: 深度学习500问，以问答形式对常用的概率知识、线性代数、机器学习、深度学习、计算机视觉等热点问题进行阐述，以帮助自己及有需要的读者。 全书分为18个章节，50余万字。由于水平有限，书中不妥之处恳请广大读者批评指正。   未完待续............ 如有意合作，联系scutjy2015@163.com                     版权所有，违权必究       Tan 2018.06

## Metadata
- Author: [github.com]()
- Title: scutan90/DeepLearning-500-questions: 深度学习500问，以问答形式对常用的概率知识、线性代数、机器学习、深度学习、计算机视觉等热点问题进行阐述，以帮助自己及有需要的读者。 全书分为18个章节，50余万字。由于水平有限，书中不妥之处恳请广大读者批评指正。   未完待续............ 如有意合作，联系scutjy2015@163.com                     版权所有，违权必究       Tan 2018.06
- Reference: https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md
- Category: #article

## Page Notes
## Highlights
- 我们应该设置一些限定条件，然后在这个范围内寻找最优解，也就是局部最优解 — [Updated on 2022-02-20 14:46:39](https://hyp.is/2wTl4pIYEeyiPfNe9FEE2Q/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 通过对已标记数据建模，在此基础上，对未标记数据进行预测。 — [Updated on 2022-02-20 14:51:29](https://hyp.is/h8ey0pIZEeyJw_OH8grTZA/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 图论推理算法（Graph Inference）或者拉普拉斯支持向量机（Laplacian SVM） — [Updated on 2022-02-20 14:51:37](https://hyp.is/jMD9IJIZEey7hssuZsLvuQ/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 弱监督学习可以看做是有多个标记的数据集合，次集合可以是空集，单个元素，或包含多种情况（没有标记，有一个标记，和有多个标记）的多个元素 — [Updated on 2022-02-20 14:52:12](https://hyp.is/odFNUJIZEeyz1Yt3f3zw4A/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 数据的好坏对于机器学习模型的预测能力至关重要，因此一般会进行数据增强。 — [Updated on 2022-02-20 14:53:18](https://hyp.is/yPTG3JIZEeyGN99bok8sqw/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

-  一般来讲，特征工程包含特征提取和特征选择 — [Updated on 2022-02-20 14:53:30](https://hyp.is/0ApzGJIZEeynNDM2-Sq3PA/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 研究者提出的不同的网络结构、正则化、归一化方法实际上就是深度学习背景下的特征工程。 — [Updated on 2022-02-20 14:54:00](https://hyp.is/4fSvJpIZEeySCesnvaE0mA/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 如何将组合特征的效能发挥出来，使原始数据在特征空间中的判别性最大化， — [Updated on 2022-02-20 14:54:15](https://hyp.is/6x-OaJIZEeyZEA_YBa64BA/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 而如何保证模型的输出和输入标签的一致性，就需要构建模型预测和标签之间的损失函数， — [Updated on 2022-02-20 14:55:10](https://hyp.is/C9lX7JIaEeyraeNsFmKQFQ/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 选择合适的模型和超参数进行初始化 — [Updated on 2022-02-20 14:55:30](https://hyp.is/F5YQ3pIaEeyhzp_XPRA_rw/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 梯度下降法及其变种，使用梯度下降法的前提是优化目标函数对于模型是可导的。 — [Updated on 2022-02-20 14:55:43](https://hyp.is/H39TRpIaEeykoD83Fct34Q/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 通常会通过调整和模型相关的各种事物（超参数）来重复步骤2和3，诸如里面有多少个节点，有多少层 — [Updated on 2022-02-20 14:57:15](https://hyp.is/VkNs5pIaEeynNlMmQ-lfyA/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 回归模型的输出是连续的 — [Updated on 2022-02-20 14:57:30](https://hyp.is/XuxUUpIaEeyNYbd0ody7Rg/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 分类模型是认为模型的输出是离散的 — [Updated on 2022-02-20 14:57:32](https://hyp.is/YDkPgJIaEeyoeNeprOgxQw/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 分对的样本数在所有样本数中的占比 — [Updated on 2022-02-20 15:19:28](https://hyp.is/cP8tEJIdEeyogP9K5RduRg/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 表示被分为正例的示例中实际为正例的比例 — [Updated on 2022-02-20 15:19:46](https://hyp.is/e3TIaJIdEeyZpte776b5wA/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 召回率是覆盖面的度量，度量有多个正例被分为正例 — [Updated on 2022-02-20 15:19:51](https://hyp.is/fr-izJIdEeyrjvf1C1gx9w/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

-  鲁棒性：处理缺失值和异常值的能力 — [Updated on 2022-02-20 15:20:09](https://hyp.is/iUvioJIdEeyNaYsfwXKzxQ/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 如何对梯度下降法进行调优 — [Updated on 2022-02-25 17:16:05](https://hyp.is/jySw2JYbEeyhNNMNu7USEw/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 算法迭代步长α\alpha选择 — [Updated on 2022-02-25 17:16:07](https://hyp.is/kGzDrpYbEeyvGGfjywuIRQ/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 参数的初始值选择。 — [Updated on 2022-02-25 17:16:09](https://hyp.is/kYyVrJYbEeyfADM9RiAmMg/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 标准化处理。  — [Updated on 2022-02-25 17:16:10](https://hyp.is/kl9AapYbEeyhNVPZLe5hIA/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation

- 随机梯度下降（SGD）和批量梯度下降（BGD）是两种主要梯度下降法 — [Updated on 2022-02-25 17:16:27](https://hyp.is/nGupNpYbEeykSTOfVHjLVw/github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md) — Group: #self-notation





