---
doc_type: hypothesis-highlights
url: 'https://blog.csdn.net/hahajinbu/article/details/81940355'
---

# 自然语言处理中的Attention机制总结 - CODE and POEM - CSDN博客

## Metadata
- Author: [blog.csdn.net]()
- Title: 自然语言处理中的Attention机制总结 - CODE and POEM - CSDN博客
- Reference: https://blog.csdn.net/hahajinbu/article/details/81940355
- Category: #article

## Page Notes
## Highlights
- decoder的输入 — [Updated on 2022-03-04 16:36:29](https://hyp.is/L_IecpuWEeyehGNSoiz-7A/blog.csdn.net/hahajinbu/article/details/81940355) — Group: #self-notation

- 上一步的隐藏状态输出 — [Updated on 2022-03-04 16:36:39](https://hyp.is/NgojIpuWEeyxcMcc13L-6g/blog.csdn.net/hahajinbu/article/details/81940355) — Group: #self-notation

- 当前步的隐藏状态 — [Updated on 2022-03-04 16:38:57](https://hyp.is/iDSXmpuWEeymAHeRLw-n9g/blog.csdn.net/hahajinbu/article/details/81940355) — Group: #self-notation

- attention的机制就是一个加权求和的机制 — [Updated on 2022-03-04 16:42:47](https://hyp.is/EVDRYJuXEeyr3peoqJxJoQ/blog.csdn.net/hahajinbu/article/details/81940355) — Group: #self-notation

- 已有信息计算的隐藏状态的加权和求和 — [Updated on 2022-03-04 16:42:56](https://hyp.is/FqnSdJuXEeyxdH-YmXg0cg/blog.csdn.net/hahajinbu/article/details/81940355) — Group: #self-notation

- 除以了一下根号dk，为了让内积不至于太大 — [Updated on 2022-03-04 16:44:35](https://hyp.is/UcKsoJuXEeyYNFNAUaLU3Q/blog.csdn.net/hahajinbu/article/details/81940355) — Group: #self-notation




